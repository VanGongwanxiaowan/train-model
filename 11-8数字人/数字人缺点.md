您询问的是 HeyGem-Linux-Python-Hack 这个数字人项目相比其他项目的缺点和技术先进性。<cite />

## 项目定位与特点

HeyGem-Linux-Python-Hack 是从 [HeyGem.ai](https://github.com/GuijiAI/HeyGem.ai) 提取出来的简化版本,专注于在 Linux 环境下运行,去除了 Docker 和 Windows 依赖。 [1](#1-0)  这个项目的主要目标是**易于部署和使用**,而不是追求最先进的技术。 [2](#1-1) 

## 主要技术限制

### 1. Python 版本限制严格
项目**仅支持 Python 3.8**,这是一个较老的版本(2019年发布)。 [3](#1-2)  这个限制主要来自于 face animation 组件的兼容性要求。 [4](#1-3) 

### 2. 模型架构相对传统
从模型文件可以看出,项目使用的是较为传统的技术栈:
- **SCRFD 人脸检测**: 使用 500M 参数的轻量级模型 [5](#1-4) 
- **ONNX 格式模型**: 虽然有利于部署,但限制了使用最新的深度学习框架特性 [6](#1-5) 
- **DI-Net (dinet_v1_20240131.pth)**: 用于 landmark 到人脸的转换,这是 2024年1月的版本 [7](#1-6) 

### 3. 环境依赖复杂
项目对 CUDA 和 ONNX Runtime 版本有严格要求,容易出现兼容性问题。 [8](#1-7)  README 中专门有一个 QA 章节处理初始化报错问题,说明环境配置并不简单。 [9](#1-8) 

### 4. 处理流程较为传统
从代码实现来看,使用的是传统的多进程队列通信方式:
- 使用 `cv2.VideoWriter` 进行视频写入 [10](#1-9) 
- 通过 `ffmpeg` 命令行工具合并音视频 [11](#1-10) 
- 手动管理队列和进程同步 [12](#1-11) 

### 5. 缺少现代化特性
- **没有实时推理优化**: 代码中有 `time.sleep(10)` 这样的硬编码延迟 [13](#1-12) 
- **批处理固定**: batch_size 固定为 4 [14](#1-13) 
- **缺少端到端优化**: 音频处理、人脸检测、动画生成是分离的模块,没有联合优化

## 相比现代数字人项目的差距

现代数字人项目(如 SadTalker、Wav2Lip、GFPGAN 等)通常具有:
- **更新的模型架构**: 使用 Transformer、Diffusion 等新技术
- **端到端训练**: 联合优化各个模块
- **更好的实时性**: 针对推理速度优化
- **更灵活的部署**: 支持多种 Python 版本和框架

## 项目优势

尽管技术相对传统,但项目也有其优势:
- **完全离线运行**: 不依赖外部 API [15](#1-14) 
- **部署简单**: 去除了 Docker 依赖,直接在 Linux 运行 [16](#1-15) 
- **代码清晰**: Python 实现,易于理解和修改 [17](#1-16) 

## Notes

这个项目更适合作为**学习和快速原型开发**的工具,而不是生产环境的最优选择。<cite /> 如果您需要最先进的数字人技术,建议关注学术界和工业界的最新研究,如基于 Diffusion 的方法或实时神经渲染技术。<cite /> 项目的技术栈确实相对传统,但这也意味着更稳定和易于部署。<cite />

Wiki pages you might want to explore:
- [Overview (Holasyb918/HeyGem-Linux-Python-Hack)](/wiki/Holasyb918/HeyGem-Linux-Python-Hack#1)
- [System Architecture (Holasyb918/HeyGem-Linux-Python-Hack)](/wiki/Holasyb918/HeyGem-Linux-Python-Hack#4)
- [Models and Resources (Holasyb918/HeyGem-Linux-Python-Hack)](/wiki/Holasyb918/HeyGem-Linux-Python-Hack#4.3)

### Citations

**File:** README.md (L16-18)
```markdown
## 项目简介

[HeyGem-Linux-Python-Hack] 是一个基于 Python 的数字人项目，它从 [HeyGem.ai](https://github.com/GuijiAI/HeyGem.ai) 中提取出来，它能够直接在 Linux 系统上运行，摆脱了对 Docker 和 Windows 系统的依赖。我们的目标是提供一个更易于部署和使用的数字人解决方案。
```

**File:** README.md (L23-29)
```markdown
## 主要特性

* 无需 Docker: 直接在 Linux 系统上运行，简化部署流程。
* 无需 Windows: 完全基于 Linux 开发和测试。
* Python 驱动: 使用 Python 语言开发，易于理解和扩展。
* 开发者友好: 易于使用和扩展。
* 完全离线。  
```

**File:** README.md (L34-35)
```markdown
本项目**支持且仅支持 Linux & python3.8 环境**  
请确保你的 Linux 系统上已经安装了 **Python 3.8**。然后，使用 pip 安装项目依赖项  
```

**File:** README.md (L71-114)
```markdown
## QA
### 1. 多个人脸报错  
下载新的人脸检测模型，替换原本的人脸检测模型或许可以解决。
```bash
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/scrfd_10g_kps.onnx
mv face_detect_utils/resources/scrfd_500m_bnkps_shape640x640.onnx face_detect_utils/resources/scrfd_500m_bnkps_shape640x640.onnx.bak
mv scrfd_10g_kps.onnx face_detect_utils/resources/scrfd_500m_bnkps_shape640x640.onnx
```
### 2. 初始化报错  

有较高概率是 onnxruntime-gpu 版本不匹配导致的。  
```bash
python check_env/check_onnx_cuda.py
```
观察输出是否包括 successfully.  
如果遇到问题，你可以尝试以下方法：
1. 建议根据自己 cuda 等环境尝试更换一些版本。  
2. 如果难以解决，先卸载 onnxruntime-gpu 和 onnxruntime，然后使用 conda 安装 cudatoolkit 环境，然后再尝试 pip 安装 onnxruntime-gpu。    

    验证可行版本如下：  
    | cudatoolkit | onnxruntime-gpu | 备注 |
    | --- | --- | --- |
    | 11.8.0 | 1.16.0 |  |

### 3. ImportError: cannot import name check_argument_types  
缺包
```bash
pip install typeguard
```
  
### 4. library.so 找不到  
报错一般是类似于 Could not load library libcublasLt.so.11. Error: libcublasLt.so.11: cannot open shared object file: No such file or directory  

执行以下命令查看是否有改文件  
```
sudo find /usr -name "libcublasLt.so.11"  
```
没有的话，应该需要安装对应版本的cuda  
如果有的话就把第一步查看的文件路径添加到环境变量  
```
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
```
永久生效就添加到 ~/.bashrc 里面然后 source ~/.bashrc 一下  

```

**File:** README_tts_f2f.MD (L32-34)
```markdown
本项目包括 tts 和 face2face 两部分
* tts 部分支持 3.8，事实上有更高版本更好；
* face2face 部分支持且仅支持 3.8。
```

**File:** download.sh (L4-28)
```shellscript
# face attr
mkdir -p face_attr_detect
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/face_attr_epoch_12_220318.onnx -O face_attr_detect/face_attr_epoch_12_220318.onnx

# face detect
mkdir -p face_detect_utils/resources
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/pfpld_robust_sim_bs1_8003.onnx -O face_detect_utils/resources/pfpld_robust_sim_bs1_8003.onnx
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/scrfd_500m_bnkps_shape640x640.onnx -O face_detect_utils/resources/scrfd_500m_bnkps_shape640x640.onnx
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/model_float32.onnx -O face_detect_utils/resources/model_float32.onnx

# dh model
mkdir -p landmark2face_wy/checkpoints/anylang
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/dinet_v1_20240131.pth -O landmark2face_wy/checkpoints/anylang/dinet_v1_20240131.pth

# face parsing
mkdir -p pretrain_models/face_lib/face_parsing
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/79999_iter.onnx -O pretrain_models/face_lib/face_parsing/79999_iter.onnx

# gfpgan
mkdir -p pretrain_models/face_lib/face_restore/gfpgan
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/GFPGANv1.4.onnx -O pretrain_models/face_lib/face_restore/gfpgan/GFPGANv1.4.onnx

# xseg
mkdir -p xseg
wget https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/releases/download/ckpts_and_onnx/xseg_211104_4790000.onnx -O xseg/xseg_211104_4790000.onnx
```

**File:** run.py (L63-86)
```python
    try:
        while True:
            state, reason, value_ = output_imgs_queue.get()
            if type(state) == bool and state == True:
                logger.info(
                    "Custom VideoWriter [{}]视频帧队列处理已结束".format(work_id)
                )
                logger.info(
                    "Custom VideoWriter Silence Video saved in {}".format(
                        os.path.realpath(output_mp4)
                    )
                )
                video_write.release()
                break
            else:
                if type(state) == bool and state == False:
                    logger.error(
                        "Custom VideoWriter [{}]任务视频帧队列 -> 异常原因:[{}]".format(
                            work_id, reason
                        )
                    )
                    raise CustomError(reason)
                for result_img in value_:
                    video_write.write(result_img)
```

**File:** run.py (L139-143)
```python
            command = "ffmpeg -loglevel warning -y -i {} -i {} -c:a aac -c:v libx264 -crf 15 -strict -2 {}".format(
                audio_path, output_mp4, result_path
            )
            logger.info("Custom command:{}".format(command))
        subprocess.call(command, shell=True)
```

**File:** run.py (L181-181)
```python
    time.sleep(10) # somehow, this works...
```

**File:** log/dh.log (L23-23)
```text
[2025-03-18 12:52:24,015] [process.py[line:108]] [INFO] [[1002]任务视频驱动队列启动 batch_size:4, len:150]
```
