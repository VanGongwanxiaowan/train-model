# 版本信息总结

## 当前配置

### ONNX Runtime 版本

- **版本**: 1.18.0 ✅
- **状态**: 已降级，正确安装
- **说明**: 这不是导致队列阻塞的原因

### num_threads 配置

- **当前值**: 0 ✅ (已修复)
- **之前值**: 4 ❌ (导致队列阻塞)
- **说明**: **这是导致队列阻塞的根本原因**

## 问题分析

### 队列阻塞的根本原因

**不是 ONNX Runtime 版本问题**，而是：

1. **`num_threads: 4` 导致 DataLoader 多进程死锁** 🔴
   - DataLoader 使用 4 个 worker 进程
   - 在多进程 CUDA 环境下，这些 worker 进程会竞争 GPU 资源
   - 导致死锁，下游处理停滞
   - 队列被填满，触发队列阻塞错误

2. **ONNX Runtime 版本**: 1.18.0 ✅ (不是问题)

## 修复措施

### 1. 修复 `num_threads` 配置 ✅

- **操作**: `num_threads: 4` → `num_threads: 0`
- **文件**: `landmark2face_wy/checkpoints/test/opt.txt`
- **状态**: ✅ 已完成

### 2. 创建自动修复脚本 ✅

- **文件**: `fix_num_threads.sh`
- **功能**: 自动检查并修复 `num_threads` 配置
- **状态**: ✅ 已创建

### 3. 重启服务 ✅

- **操作**: 重启 Gradio 服务以应用新配置
- **状态**: ✅ 已完成

## 验证结果

### 配置验证

```bash
# num_threads 配置
num_threads: 0  ✅

# ONNX Runtime 版本
onnxruntime-gpu: 1.18.0  ✅
```

## 为什么必须使用 `num_threads: 0`？

### 技术原因

1. **避免多进程死锁**: `num_threads: 0` 强制 DataLoader 使用单进程，避免多进程 CUDA 环境下的死锁
2. **队列阻塞问题**: 多进程死锁导致下游处理停滞，队列被填满
3. **性能影响**: 虽然单进程可能稍慢，但在多进程 CUDA 环境下更稳定

## 防止再次发生

### 自动修复脚本

使用 `fix_num_threads.sh` 脚本可以：
1. 自动检查 `num_threads` 配置
2. 如果不是 0，自动修复为 0
3. 创建备份文件

### 使用方式

```bash
# 在容器内执行
docker exec starpainting-digital-human-service-1 bash -c "/app/HeyGem-Linux-Python-Hack/fix_num_threads.sh"
```

## 更新日期

2025-11-09

