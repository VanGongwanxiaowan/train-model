# æ•°å­—äººDockerç¯å¢ƒCUDAç‰ˆæœ¬ä¿¡æ¯

## ğŸ“‹ CUDAç‰ˆæœ¬æ€»ç»“

### 1. PyTorchä½¿ç”¨çš„CUDAç‰ˆæœ¬
- **CUDAç‰ˆæœ¬**: **11.3**
- **PyTorchç‰ˆæœ¬**: 1.11.0+cu113
- **è¯´æ˜**: PyTorchæ˜¯ä¸ºCUDA 11.3ç¼–è¯‘çš„ï¼Œè‡ªå¸¦CUDA 11.3åº“

### 2. Condaç¯å¢ƒä¸­å®‰è£…çš„CUDAå·¥å…·åŒ…
- **cudatoolkitç‰ˆæœ¬**: **11.8.0**
- **å®‰è£…æ–¹å¼**: condaå®‰è£…
- **å®‰è£…è·¯å¾„**: `/opt/conda/envs/human/lib`
- **ç”¨é€”**: ä¸ºONNX Runtime GPUæä¾›CUDAåº“æ”¯æŒ

### 3. cuDNNç‰ˆæœ¬
- **cuDNNç‰ˆæœ¬**: **8.9.2.26** (cuDNN 8.xç³»åˆ—)
- **å®‰è£…æ–¹å¼**: condaå®‰è£…
- **å®‰è£…è·¯å¾„**: `/opt/conda/envs/human/lib`
- **è¯´æ˜**: cuDNN 8.xä¸CUDA 11.xå…¼å®¹

### 4. ç³»ç»ŸCUDAç‰ˆæœ¬ï¼ˆå®¿ä¸»æœºå™¨ï¼‰
- **å¯èƒ½ç‰ˆæœ¬**: CUDA 12.xï¼ˆæ ¹æ®æ–‡æ¡£æ¨æµ‹ï¼‰
- **è¯´æ˜**: ç³»ç»Ÿå¯èƒ½å®‰è£…äº†CUDA 12.xï¼Œä½†PyTorchä¼šä½¿ç”¨è‡ªå¸¦çš„CUDA 11.3åº“ï¼Œä¸ä¼šä½¿ç”¨ç³»ç»ŸCUDA

## ğŸ” è¯¦ç»†çš„CUDAç‰ˆæœ¬ä¿¡æ¯

### PyTorch CUDAç‰ˆæœ¬
```python
import torch
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")  # 1.11.0+cu113
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")  # True
print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")  # 11.3
print(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")  # å¯¹åº”cuDNNç‰ˆæœ¬
```

### ONNX Runtime GPU CUDAç‰ˆæœ¬
- **ONNX Runtime GPUç‰ˆæœ¬**: 1.16.0
- **éœ€è¦çš„CUDAç‰ˆæœ¬**: CUDA 11.x
- **éœ€è¦çš„cuDNNç‰ˆæœ¬**: cuDNN 8.x
- **çŠ¶æ€**: âœ… å·²é…ç½®ï¼Œä½¿ç”¨cudatoolkit 11.8.0

## ğŸ“Š ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ

| ç»„ä»¶ | ç‰ˆæœ¬ | CUDAè¦æ±‚ | çŠ¶æ€ |
|------|------|----------|------|
| **PyTorch** | 1.11.0+cu113 | CUDA 11.3 | âœ… åŒ¹é… |
| **cudatoolkit** | 11.8.0 | CUDA 11.8 | âœ… å…¼å®¹ï¼ˆå‘åå…¼å®¹11.3ï¼‰ |
| **cuDNN** | 8.9.2.26 | cuDNN 8.x | âœ… åŒ¹é… |
| **ONNX Runtime GPU** | 1.16.0 | CUDA 11.x | âœ… å…¼å®¹ |
| **ç³»ç»ŸCUDA** | 12.x (æ¨æµ‹) | - | âš ï¸ ä¸ä½¿ç”¨ï¼ˆPyTorchä½¿ç”¨è‡ªå¸¦åº“ï¼‰ |

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

### å¿…éœ€çš„ç¯å¢ƒå˜é‡
```bash
export LD_LIBRARY_PATH=/opt/conda/envs/human/lib:$LD_LIBRARY_PATH
```

### ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Ÿ
ONNX Runtime GPUéœ€è¦æ‰¾åˆ°ä»¥ä¸‹CUDAåº“ï¼š
- `libcublasLt.so.11` (CUDA 11.8)
- `libcudnn.so.8` (cuDNN 8.9)

è¿™äº›åº“å·²å®‰è£…åœ¨ `/opt/conda/envs/human/lib` ç›®å½•ä¸­ï¼Œéœ€è¦é€šè¿‡ `LD_LIBRARY_PATH` å‘Šè¯‰ç³»ç»Ÿåœ¨å“ªé‡ŒæŸ¥æ‰¾è¿™äº›åº“ã€‚

## âœ… éªŒè¯CUDAç‰ˆæœ¬

### æ–¹æ³•1: é€šè¿‡PyTorchéªŒè¯
```bash
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && python -c 'import torch; print(f\"PyTorch: {torch.__version__}\"); print(f\"CUDA available: {torch.cuda.is_available()}\"); print(f\"CUDA version: {torch.version.cuda}\")'"
```

### æ–¹æ³•2: æ£€æŸ¥cudatoolkitç‰ˆæœ¬
```bash
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && conda list cudatoolkit"
```

### æ–¹æ³•3: æ£€æŸ¥cuDNNç‰ˆæœ¬
```bash
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && conda list cudnn"
```

### æ–¹æ³•4: æ£€æŸ¥CUDAåº“æ–‡ä»¶
```bash
docker exec starpainting-digital-human-service-1 bash -c "ls -la /opt/conda/envs/human/lib/libcublas*.so*"
docker exec starpainting-digital-human-service-1 bash -c "ls -la /opt/conda/envs/human/lib/libcudnn*.so*"
```

### æ–¹æ³•5: æ£€æŸ¥ç³»ç»ŸCUDAç‰ˆæœ¬ï¼ˆå¦‚æœå®‰è£…äº†nvidia-smiï¼‰
```bash
docker exec starpainting-digital-human-service-1 bash -c "nvidia-smi"
# æˆ–è€…
docker exec starpainting-digital-human-service-1 bash -c "nvcc --version"
```

## ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **PyTorchä½¿ç”¨CUDA 11.3**
   - PyTorch 1.11.0+cu113è‡ªå¸¦CUDA 11.3åº“
   - ä¸ä¾èµ–ç³»ç»ŸCUDAç‰ˆæœ¬
   - å³ä½¿ç³»ç»Ÿæœ‰CUDA 12.xï¼ŒPyTorchä»ä½¿ç”¨è‡ªå¸¦çš„CUDA 11.3

2. **ONNX Runtimeä½¿ç”¨CUDA 11.8**
   - é€šè¿‡condaå®‰è£…çš„cudatoolkit 11.8.0æä¾›CUDAåº“
   - CUDA 11.8å‘åå…¼å®¹CUDA 11.3
   - éœ€è¦è®¾ç½®LD_LIBRARY_PATHæ‰èƒ½æ‰¾åˆ°CUDAåº“

3. **cuDNN 8.x**
   - cuDNN 8.9.2.26ä¸CUDA 11.xå…¼å®¹
   - å·²é€šè¿‡condaå®‰è£…

4. **ç‰ˆæœ¬å…¼å®¹æ€§**
   - âœ… PyTorch CUDA 11.3 + cudatoolkit 11.8.0 = å…¼å®¹
   - âœ… ONNX Runtime GPU 1.16.0 + CUDA 11.x = å…¼å®¹
   - âœ… cuDNN 8.x + CUDA 11.x = å…¼å®¹

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸è¦å‡çº§CUDAç‰ˆæœ¬**
   - PyTorch 1.11.0+cu113å¿…é¡»ä½¿ç”¨CUDA 11.3
   - å‡çº§åˆ°CUDA 12.xä¼šå¯¼è‡´PyTorchæ— æ³•å·¥ä½œ

2. **ç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®**
   - å¿…é¡»è®¾ç½® `LD_LIBRARY_PATH=/opt/conda/envs/human/lib`
   - å¦åˆ™ONNX Runtime GPUæ— æ³•æ‰¾åˆ°CUDAåº“

3. **ç³»ç»ŸCUDAç‰ˆæœ¬ä¸å½±å“**
   - å³ä½¿ç³»ç»Ÿæœ‰CUDA 12.xï¼Œä¹Ÿä¸ä¼šå½±å“PyTorch
   - PyTorchä½¿ç”¨è‡ªå¸¦çš„CUDA 11.3åº“

4. **Docker GPUæ”¯æŒ**
   - ç¡®ä¿Dockeræ”¯æŒGPUï¼ˆnvidia-dockeræˆ–--gpusé€‰é¡¹ï¼‰
   - ç¡®ä¿NVIDIAé©±åŠ¨ç‰ˆæœ¬æ”¯æŒCUDA 11.3

## ğŸ“ ç›¸å…³æ–‡ä»¶

- `Dockerfile` - Dockeré•œåƒé…ç½®
- `ONNX_Runtime_GPUé…ç½®è¯´æ˜.md` - ONNX Runtime GPUé…ç½®è¯¦æƒ…
- `ç¯å¢ƒä¿®å¤å®ŒæˆæŠ¥å‘Š.md` - ç¯å¢ƒä¿®å¤è®°å½•
- `ç¯å¢ƒä¿®å¤æ€»ç»“.md` - ç¯å¢ƒä¿®å¤æ€»ç»“

## ğŸ“… æ–‡æ¡£ç”Ÿæˆæ—¥æœŸ

2025-01-27

