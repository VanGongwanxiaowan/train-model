# 稳定运行配置总结

## 配置目标

**确保服务平稳运行，避免队列阻塞问题**

## 关键配置

### 1. num_threads 配置 ✅

- **配置值**: `num_threads: 0`
- **文件**: `landmark2face_wy/checkpoints/test/opt.txt`
- **原因**: 避免多进程 CUDA 环境下的死锁问题
- **状态**: ✅ 已配置

### 2. ONNX Runtime 版本 ✅

- **版本**: `onnxruntime-gpu: 1.18.0`
- **原因**: 稳定版本，避免队列阻塞问题
- **状态**: ✅ 已降级

### 3. 环境变量配置 ✅

在 `app.py` 中已设置：

- `ORT_PARALLEL=0` - 禁用 ONNX Runtime 并行
- `TORCH_DATALOADER_NUM_WORKERS=0` - 强制 DataLoader 使用单进程
- `OMP_NUM_THREADS=1` - 限制 OpenMP 线程数
- `TORCH_NUM_THREADS=1` - 限制 PyTorch 线程数
- `GRADIO_QUEUE_TIMEOUT=300` - 队列超时时间（5分钟）
- `CUDA_LAUNCH_BLOCKING=0` - 异步执行 CUDA 操作

### 4. Docker 共享内存 ✅

- **配置**: `--shm-size=2g`
- **原因**: 增加共享内存，避免多进程问题
- **状态**: ✅ 已配置

### 5. Gradio 队列配置 ✅

- `max_size=10` - 最大队列大小
- `default_concurrency_limit=1` - 并发限制
- `api_open=False` - 关闭 API 访问

## 稳定性措施

### 1. 避免多进程死锁

- **num_threads: 0**: 使用单进程模式，避免多进程死锁
- **TORCH_DATALOADER_NUM_WORKERS=0**: 强制 DataLoader 使用单进程
- **ORT_PARALLEL=0**: 禁用 ONNX Runtime 并行

### 2. 资源管理

- **限制线程数**: 所有线程数限制为 1，避免资源竞争
- **共享内存**: 增加 Docker 共享内存到 2GB
- **队列配置**: 限制队列大小和并发数

### 3. 错误处理

- **队列超时**: 设置 5 分钟超时时间
- **错误日志**: 记录详细错误信息
- **自动修复**: 使用 `fix_num_threads.sh` 脚本自动修复配置

## 监控建议

### 1. 日志监控

```bash
# 监控服务日志
docker exec starpainting-digital-human-service-1 tail -f /app/HeyGem-Linux-Python-Hack/log/dh.log

# 监控 Gradio 日志
docker exec starpainting-digital-human-service-1 tail -f /tmp/gradio.log
```

### 2. 性能监控

```bash
# 检查服务进程
docker exec starpainting-digital-human-service-1 ps aux | grep 'python app.py'

# 检查 GPU 使用情况
docker exec starpainting-digital-human-service-1 nvidia-smi

# 检查服务状态
curl http://192.168.191.56:7860/
```

### 3. 配置验证

```bash
# 验证 num_threads 配置
docker exec starpainting-digital-human-service-1 bash -c "cat /app/HeyGem-Linux-Python-Hack/landmark2face_wy/checkpoints/test/opt.txt | grep num_threads"

# 验证 ONNX Runtime 版本
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && pip show onnxruntime-gpu | grep Version"
```

## 故障排查

### 如果出现队列阻塞

1. **检查 num_threads 配置**
   ```bash
   docker exec starpainting-digital-human-service-1 bash -c "/app/HeyGem-Linux-Python-Hack/fix_num_threads.sh"
   ```

2. **检查服务状态**
   ```bash
   docker exec starpainting-digital-human-service-1 ps aux | grep 'python app.py'
   ```

3. **查看日志**
   ```bash
   docker exec starpainting-digital-human-service-1 tail -50 /app/HeyGem-Linux-Python-Hack/log/dh.log
   ```

4. **重启服务**
   ```bash
   # 停止服务
   docker exec starpainting-digital-human-service-1 bash -c "ps aux | grep 'python app.py' | grep -v grep | awk '{print \$2}' | xargs -r kill"
   
   # 启动服务
   docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && cd /app/HeyGem-Linux-Python-Hack && nohup python app.py > /tmp/gradio.log 2>&1 &"
   ```

## 自动修复脚本

### fix_num_threads.sh

自动检查和修复 `num_threads` 配置：

```bash
docker exec starpainting-digital-human-service-1 bash -c "/app/HeyGem-Linux-Python-Hack/fix_num_threads.sh"
```

## 配置清单

### 必须配置

- ✅ `num_threads: 0` - 避免多进程死锁
- ✅ `onnxruntime-gpu: 1.18.0` - 稳定版本
- ✅ `ORT_PARALLEL=0` - 禁用并行
- ✅ `TORCH_DATALOADER_NUM_WORKERS=0` - 单进程模式
- ✅ Docker 共享内存 `--shm-size=2g`

### 推荐配置

- ✅ `OMP_NUM_THREADS=1` - 限制线程数
- ✅ `TORCH_NUM_THREADS=1` - 限制线程数
- ✅ `GRADIO_QUEUE_TIMEOUT=300` - 队列超时
- ✅ Gradio 队列配置 `max_size=10`, `default_concurrency_limit=1`

## 性能考虑

### 单进程模式 vs 多进程模式

- **单进程模式** (`num_threads: 0`):
  - ✅ 稳定，不会死锁
  - ✅ 避免队列阻塞
  - ⚠️ 可能稍慢，但更可靠

- **多进程模式** (`num_threads > 0`):
  - ✅ 理论上更快
  - ❌ 容易死锁
  - ❌ 导致队列阻塞
  - ❌ 不适合多进程 CUDA 环境

**结论**: 为了稳定运行，优先选择单进程模式。

## 总结

### 当前配置状态

- ✅ `num_threads: 0` - 已配置
- ✅ `onnxruntime-gpu: 1.18.0` - 已降级
- ✅ 环境变量 - 已设置
- ✅ Docker 共享内存 - 已增加
- ✅ Gradio 队列配置 - 已优化

### 稳定性保证

1. **避免死锁**: 使用单进程模式
2. **避免队列阻塞**: 优化配置和环境变量
3. **资源管理**: 限制线程数和队列大小
4. **错误处理**: 设置超时和日志记录
5. **自动修复**: 提供修复脚本

### 下一步

1. **监控服务**: 定期检查服务状态和日志
2. **性能测试**: 测试数字人生成功能
3. **故障排查**: 如果出现问题，按照故障排查步骤处理

## 相关文件

- `num_threads配置详细说明.md` - 详细配置说明
- `fix_num_threads.sh` - 自动修复脚本
- `队列阻塞问题最终解决方案_2025-11-09.md` - 解决方案
- `服务重启报告_2025-11-09.md` - 服务重启报告

## 更新日期

2025-11-09

