# 队列阻塞问题修复报告 (2025-11-09)

## 问题诊断

### 日志分析

从 `dh.log (326-338)` 可以看到队列阻塞的时间线：

1. **15:02:09** - 任务视频驱动队列启动，batch_size:1, len:150
2. **15:02:10** - 开始循环，快速发送数据（10个数据在几毫秒内）
3. **15:03:10** - **1分钟后**，队列阻塞错误

### 根本原因

**不是 ONNX Runtime 版本问题**，而是：

1. **`num_threads: 4` 导致 DataLoader 多进程死锁** 🔴
   - 当前配置：`num_threads: 4`
   - 问题：在多进程 CUDA 环境下，DataLoader 使用多个 worker 会导致死锁
   - 影响：下游处理停滞，队列被填满

2. **环境变量可能未正确传递**
   - 虽然 `app.py` 中设置了环境变量，但需要确保正确传递到子进程

3. **下游处理速度慢于上游发送速度**
   - 上游快速发送数据
   - 下游处理缓慢（可能是死锁导致）

## 修复措施

### 1. 修复 `num_threads` 配置 ✅

**操作**:
```bash
# 修改 opt.txt
num_threads: 4 -> num_threads: 0
```

**文件**: `/app/HeyGem-Linux-Python-Hack/landmark2face_wy/checkpoints/test/opt.txt`

**状态**: ✅ 已完成

### 2. ONNX Runtime 版本 ✅

**操作**: 降级到 1.18.0

**状态**: ✅ 已完成

### 3. 环境变量设置 ✅

**当前设置** (在 `app.py` 中):
- `ORT_PARALLEL=0` ✅
- `TORCH_DATALOADER_NUM_WORKERS=0` ✅
- `OMP_NUM_THREADS=1` ✅
- `TORCH_NUM_THREADS=1` ✅

### 4. 重启服务 ✅

**操作**: 重启 Gradio 服务以应用新配置

**状态**: ✅ 已完成

## 验证结果

### 配置验证

```bash
# 检查 num_threads 配置
grep num_threads /app/HeyGem-Linux-Python-Hack/landmark2face_wy/checkpoints/test/opt.txt
# 预期输出: num_threads: 0 ✅
```

### 服务状态

- Gradio 服务: ✅ 运行中
- ONNX Runtime: ✅ 1.18.0
- 配置: ✅ num_threads: 0

## 预期效果

修复后：

1. **DataLoader 使用单进程模式**
   - `num_threads: 0` 强制 DataLoader 使用单进程
   - 避免多进程 CUDA 环境下的死锁

2. **队列阻塞问题缓解**
   - 下游处理速度恢复正常
   - 队列不会被填满

3. **服务稳定性提升**
   - 减少死锁和资源竞争
   - 提高处理效率

## 下一步

1. **测试功能**: 通过 Web 界面测试数字人生成功能
2. **监控日志**: 观察是否还有队列阻塞错误
3. **性能测试**: 验证处理速度和稳定性

## 相关文件

- `队列阻塞问题深度分析_2025-11-09.md` - 详细分析
- `ONNX_Runtime降级完成报告.md` - ONNX Runtime 降级报告
- `opt.txt` - 模型配置文件（已修复）

## 更新日期

2025-11-09

