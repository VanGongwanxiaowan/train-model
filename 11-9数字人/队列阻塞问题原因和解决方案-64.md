# 队列阻塞问题原因和解决方案

## 问题描述

### 日志分析
```
[2025-11-09 17:29:40,287] [INFO] [drivered_video >>>>>>>>>>>>>>>>>>>> 发送数据大小:[1], current_idx:1]
[2025-11-09 17:29:40,322] [INFO] [drivered_video >>>>>>>>>>>>>>>>>>>> 发送数据大小:[1], current_idx:10]
[2025-11-09 17:30:40,324] [ERROR] [任务视频驱动队列满，严重阻塞，下游队列异常]
```

### 问题现象
1. **数据发送**: 成功发送了10个数据（current_idx:1 到 current_idx:10）
2. **阻塞时间**: 60秒后（17:29:40 到 17:30:40）出现队列阻塞
3. **错误信息**: "任务视频驱动队列满，严重阻塞，下游队列异常"
4. **GPU 利用率**: **0%** ❌（所有 GPU 利用率都为 0%）

## 根本原因

### 核心问题：GPU 未被使用

#### 为什么 GPU 未被使用？

1. **处理速度慢导致队列阻塞**
   - **GPU 处理**: 每帧可能需要几毫秒到几十毫秒
   - **CPU 处理**: 每帧可能需要几秒到几十秒
   - **速度差距**: GPU 比 CPU 快 10-100 倍
   - **问题**: 如果使用 CPU，处理 150 帧视频需要很长时间

2. **队列阻塞机制**
   - **数据产生速度快**: 视频帧数据快速进入队列（batch_size:1, len:150）
   - **处理速度慢**: CPU 处理速度远慢于数据产生速度
   - **队列填满**: 队列快速填满（仅处理了 10/150 个数据）
   - **阻塞**: 队列填满后阻塞，无法继续处理

3. **具体分析**
   - **总数据量**: 150 帧
   - **已处理**: 10 帧（6.7%）
   - **处理时间**: 60 秒
   - **处理速度**: 约 0.17 帧/秒（CPU 处理）
   - **预计总时间**: 150 / 0.17 ≈ 882 秒（约 15 分钟）
   - **队列阻塞**: 60 秒后队列填满，阻塞

### 为什么 GPU 未被使用？

#### 可能原因 1: 环境变量未正确传递
- **问题**: 服务启动时 LD_LIBRARY_PATH 可能没有正确设置
- **影响**: ONNX Runtime 无法找到 cuDNN 库，回退到 CPU
- **验证**: 需要检查服务进程的环境变量

#### 可能原因 2: trans_dh_service.so 导入时未找到库
- **问题**: trans_dh_service.so 是编译后的文件，在导入时如果 LD_LIBRARY_PATH 未设置，可能无法找到 cuDNN 库
- **影响**: 即使后来设置了环境变量，.so 文件已经加载，无法使用 GPU
- **验证**: 需要检查 .so 文件的依赖

#### 可能原因 3: 多进程环境下环境变量未传递
- **问题**: multiprocessing.spawn 方式创建的子进程可能没有正确继承环境变量
- **影响**: 子进程无法使用 GPU
- **验证**: 需要检查子进程的环境变量

#### 可能原因 4: ONNX Runtime 实际运行时回退到 CPU
- **问题**: 虽然检查脚本显示 GPU 可用，但实际运行时可能因为环境变量问题回退到 CPU
- **影响**: ONNX Runtime 使用 CPU，处理速度慢
- **验证**: 需要检查实际运行时的 GPU 使用情况

## 解决方案

### 方案 1: 使用启动脚本确保环境变量正确设置（最关键）

#### 问题
- 服务启动时 LD_LIBRARY_PATH 必须正确设置
- trans_dh_service.so 导入时需要能找到 cuDNN 库

#### 解决方案
使用启动脚本 `启动服务.sh`，确保环境变量在导入 .so 文件之前设置：
```bash
#!/bin/bash
source /opt/conda/etc/profile.d/conda.sh
conda activate human
export LD_LIBRARY_PATH=/opt/conda/envs/human/lib:$LD_LIBRARY_PATH
export ORT_PARALLEL=0
export OMP_WAIT_POLICY=ACTIVE
export ORT_LOGGING_LEVEL=3
cd /app/HeyGem-Linux-Python-Hack
python app.py
```

#### 为什么有效？
- **确保环境变量设置**: 启动脚本确保所有环境变量在导入 .so 文件之前设置
- **传递给子进程**: 环境变量会传递给所有子进程
- **ONNX Runtime 能找到库**: LD_LIBRARY_PATH 确保 cuDNN 库能被找到

### 方案 2: 在 app.py 中提前设置环境变量

#### 问题
- app.py 中环境变量设置可能在导入 trans_dh_service 之后
- 需要确保在导入之前设置

#### 解决方案
在 app.py 开头，在所有导入之前设置环境变量：
```python
# 在所有导入之前设置环境变量
import os
conda_lib_path = "/opt/conda/envs/human/lib"
current_ld_path = os.environ.get("LD_LIBRARY_PATH", "")
if conda_lib_path not in current_ld_path:
    if current_ld_path:
        os.environ["LD_LIBRARY_PATH"] = f"{conda_lib_path}:{current_ld_path}"
    else:
        os.environ["LD_LIBRARY_PATH"] = conda_lib_path
    os.putenv("LD_LIBRARY_PATH", os.environ["LD_LIBRARY_PATH"])
```

#### 为什么有效？
- **提前设置**: 在所有导入之前设置环境变量
- **确保 .so 文件能找到库**: trans_dh_service.so 导入时能找到 cuDNN 库
- **传递给子进程**: 环境变量会传递给所有子进程

### 方案 3: 增加超时时间和队列大小（临时方案）

#### 问题
- 即使 GPU 未使用，也需要确保队列不会过早阻塞
- 需要增加队列大小和超时时间

#### 解决方案
1. **增加队列大小**: 从 10 增加到 20 ✅
2. **增加超时时间**: 从 60秒 增加到 180秒 ✅
3. **增加任务等待时间**: 从 600秒 增加到 900秒 ✅

#### 为什么有效？
- **允许更多任务排队**: 减少队列填满的概率
- **给 GPU 更多处理时间**: 即使处理慢，也不会过早阻塞
- **提高任务成功率**: 减少误判失败

## 实施步骤

### 步骤 1: 使用启动脚本重启服务 ✅

```bash
# 停止服务
ps aux | grep 'python app.py' | grep -v grep | awk '{print $2}' | xargs -r kill -9

# 使用启动脚本重启服务
bash /app/HeyGem-Linux-Python-Hack/启动服务.sh
```

### 步骤 2: 验证环境变量 ✅

```bash
# 检查服务进程的环境变量
ps e -p $(ps aux | grep 'python app.py' | grep -v grep | awk '{print $2}') | grep LD_LIBRARY_PATH
```

### 步骤 3: 监控 GPU 使用 ⏳

```bash
# 监控 GPU 使用
watch -n 1 'nvidia-smi --query-gpu=index,utilization.gpu,memory.used --format=csv'
```

### 步骤 4: 测试任务执行 ⏳

- 提交测试任务
- 观察 GPU 使用情况
- 检查队列阻塞情况

## 预期结果

### 如果 GPU 正常使用
- GPU 利用率 > 0%
- 处理速度应该很快（每帧几毫秒）
- 队列不应该阻塞
- 150 帧视频应该在几分钟内完成

### 如果 GPU 未使用
- GPU 利用率为 0%
- 处理速度慢（每帧几秒）
- 队列容易阻塞
- 150 帧视频可能需要几十分钟

## 总结

### 根本原因
**GPU 未被使用** - 这是队列阻塞的根本原因
- GPU 利用率为 0%
- 任务在 CPU 上运行
- 处理速度慢，导致队列阻塞

### 关键问题
1. **环境变量传递**: 子进程可能没有正确继承环境变量
2. **.so 文件加载**: trans_dh_service.so 导入时可能无法找到 cuDNN 库
3. **多进程环境**: multiprocessing.spawn 方式可能有问题

### 解决方案
1. **使用启动脚本**: 确保环境变量在导入 .so 文件之前设置
2. **提前设置环境变量**: 在 app.py 开头设置环境变量
3. **增加超时时间**: 给 GPU 更多处理时间
4. **监控 GPU 使用**: 验证 GPU 是否被使用

### 为什么这些修复有效？

1. **使用启动脚本**
   - 确保环境变量在导入 .so 文件之前设置
   - trans_dh_service.so 导入时能找到 cuDNN 库
   - ONNX Runtime 能使用 GPU

2. **提前设置环境变量**
   - 在所有导入之前设置环境变量
   - 确保 .so 文件能找到库
   - 传递给子进程

3. **增加超时时间**
   - 给 GPU 足够的处理时间
   - 避免过早判定失败
   - 提高任务成功率

## 下一步

### 立即行动
1. **使用启动脚本**: 使用启动脚本重启服务
2. **验证环境变量**: 验证服务进程的环境变量
3. **监控 GPU 使用**: 监控 GPU 利用率
4. **测试任务执行**: 提交测试任务，观察 GPU 使用情况

### 后续优化
1. **优化环境变量传递**: 确保子进程能正确继承环境变量
2. **监控 GPU 使用**: 持续监控 GPU 使用情况
3. **优化队列配置**: 根据实际情况调整配置
4. **性能测试**: 进行完整的性能测试

