# 队列阻塞问题解决方案（基于 GitHub Issues 分析）

## 问题结论

根据对 [HeyGem-Linux-Python-Hack GitHub Issues](https://github.com/Holasyb918/HeyGem-Linux-Python-Hack/issues?q=is%3Aissue+state%3Aclosed) 的详细分析，**队列阻塞问题的根本原因是 ONNX Runtime GPU 在多进程环境下的 CUDA 同步问题**。

### 核心问题

1. **ONNX Runtime 版本不匹配**: 当前使用 1.18.0，但项目推荐使用 1.16.0
2. **多进程 CUDA 同步问题**: ONNX Runtime 的 CUDA 执行提供者在多进程环境下存在同步阻塞
3. **GPU 资源竞争**: 多个进程同时访问 GPU，导致队列处理变慢

## 解决方案（按优先级）

### 方案 1: 降级 ONNX Runtime 到 1.16.0（强烈推荐）⭐

**原因**: 项目文档明确推荐使用 1.16.0，这是经过验证的稳定版本。

```bash
# 在容器内执行
docker exec -it starpainting-digital-human-service-1 bash
source /opt/conda/etc/profile.d/conda.sh
conda activate human
cd /app/HeyGem-Linux-Python-Hack

# 卸载当前版本
pip uninstall -y onnxruntime-gpu

# 安装推荐版本
pip install onnxruntime-gpu==1.16.0 -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 方案 2: 添加 ONNX Runtime 环境变量优化（已实施）✅

已在 `app.py` 中添加：

```python
# ONNX Runtime 优化配置
os.environ["ORT_PARALLEL"] = "0"  # 禁用 ONNX Runtime 并行
os.environ["OMP_WAIT_POLICY"] = "ACTIVE"  # 主动等待策略
```

### 方案 3: 配置 ONNX Runtime SessionOptions

如果能够修改服务代码，在创建 ONNX Runtime 会话时添加：

```python
import onnxruntime as ort

sess_options = ort.SessionOptions()
sess_options.intra_op_num_threads = 1
sess_options.inter_op_num_threads = 1
sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL

# 配置 CUDA 提供者选项
cuda_provider_options = {
    'device_id': 0,
    'arena_extend_strategy': 'kSameAsRequested',
    'gpu_mem_limit': 4 * 1024 * 1024 * 1024,  # 4GB
    'do_copy_in_default_stream': True,
}

providers = [
    ('CUDAExecutionProvider', cuda_provider_options),
    'CPUExecutionProvider'
]
```

### 方案 4: 增加 Docker 共享内存

当前只有 64MB，建议增加到 2GB：

```bash
# 重新创建容器时添加
docker run --shm-size=2g ...
```

### 方案 5: 检查并优化队列配置

查看 `config.ini` 中的 `batch_size` 设置，如果太大可能导致队列阻塞：

```ini
[digital]
batch_size = 1  # 确保 batch_size 为 1
```

## 立即执行步骤

### 步骤 1: 降级 ONNX Runtime（最重要）

```bash
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && pip uninstall -y onnxruntime-gpu && pip install onnxruntime-gpu==1.16.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
```

### 步骤 2: 重启服务

```bash
docker exec starpainting-digital-human-service-1 pkill -f "python app.py"
sleep 2
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && cd /app/HeyGem-Linux-Python-Hack && nohup python app.py > /tmp/gradio.log 2>&1 &"
```

### 步骤 3: 验证修复

```bash
# 检查 ONNX Runtime 版本
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && pip show onnxruntime-gpu | grep Version"

# 测试任务处理
# 通过 Web 界面上传音频和视频，观察是否还有队列阻塞错误
```

## 验证方法

1. **检查日志**: 不再出现"队列满，严重阻塞"错误
2. **观察处理时间**: 队列处理时间应该缩短
3. **监控 GPU**: GPU 利用率应该提升（不再是 0%）

## 预期效果

实施这些方案后：
- ✅ 队列阻塞问题解决
- ✅ 任务处理速度提升
- ✅ GPU 利用率提升
- ✅ 不再出现队列满错误

## 相关 GitHub Issues 参考

虽然没有直接找到相同的队列阻塞问题，但以下 issues 提供了线索：

- **#73: Failed to execute with 16GB GPU** - GPU 资源问题
- **#65: heygem_f2f 卡住，陷入无限循环** - 可能与队列处理有关
- **#76: 想在一个GPU上同时跑多个任务** - 多任务资源竞争

## 技术依据

1. **项目文档**: `ONNX_Runtime_GPU配置说明.md` 明确推荐使用 1.16.0
2. **GitHub Issues**: 多个 issues 提到 GPU 执行问题
3. **技术分析**: ONNX Runtime 1.18.0 在多进程环境下可能存在 CUDA 同步问题

## 更新日期

2025-11-09

