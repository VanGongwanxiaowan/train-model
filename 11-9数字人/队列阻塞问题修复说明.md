# 队列阻塞问题修复说明

## 问题描述

运行过程中遇到"任务视频驱动队列满，严重阻塞，下游队列异常"的错误。

## 根本原因分析

1. **PyTorch 版本不兼容**：PyTorch 2.4.1+cu118 可能存在多进程队列处理问题
2. **多进程/多线程冲突**：OpenCV 和 PyTorch 在多进程环境下存在线程安全问题
3. **共享内存不足**：Docker 容器默认共享内存可能不足以支持多进程数据加载
4. **环境变量配置不当**：未正确设置线程数限制，导致资源竞争

## 修复方案

### 1. PyTorch 版本回退

将 PyTorch 从 2.4.1+cu118 回退到稳定版本 2.1.2+cu118：

```bash
# 在 requirements_0.txt 中已更新
torch==2.1.2+cu118
torchaudio==2.1.2+cu118
torchvision==0.16.2+cu118
triton==2.1.0
```

### 2. 相关依赖版本调整

匹配稳定配置的依赖版本：

- numpy==1.22.4（从 1.24.4 降级）
- opencv-python==4.7.0.72（从 4.11.0.86 降级）
- librosa==0.8.1（从 0.11.0 降级）
- numba==0.55.2（从 0.58.1 降级）
- scikit-image==0.19.3（从 0.21.0 降级）
- scikit-learn==1.0.2（从 1.3.2 降级）
- pillow==9.1.1（从 10.4.0 降级）
- typeguard==2.13.3（已存在）

### 3. 多进程/多线程优化

在 `app.py` 中添加了以下优化配置：

#### 环境变量设置（在导入 OpenCV 和 PyTorch 之前）

```python
os.environ["OPENCV_OPENCL_RUNTIME"] = ""
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"
os.environ["TORCH_NUM_THREADS"] = "1"
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"
```

#### OpenCV 单线程配置

```python
cv2.setNumThreads(0)
cv2.ocl.setUseOpenCL(False)
```

### 4. Docker 共享内存配置

在启动 Docker 容器时，需要增加共享内存大小：

```bash
docker run -d \
  --name starpainting-digital-human-service-1 \
  --gpus all \
  --shm-size=2g \
  -p 8308:8308 \
  -p 7860:7860 \
  -v /data2/home_back/gujiaxin/work/starpainting/backend/services/digital-human-service:/app \
  heygem:v2.2
```

**关键参数**：`--shm-size=2g`（建议至少 1GB，推荐 2GB）

### 5. 安装步骤

1. **更新依赖**

```bash
# 进入容器
docker exec -it starpainting-digital-human-service-1 bash

# 激活 conda 环境
source /opt/conda/etc/profile.d/conda.sh
conda activate human

# 进入项目目录
cd /app/HeyGem-Linux-Python-Hack

# 卸载旧版本的 PyTorch
pip uninstall -y torch torchvision torchaudio

# 安装新版本的 PyTorch（使用 CUDA 11.8）
pip install torch==2.1.2+cu118 torchvision==0.16.2+cu118 torchaudio==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118

# 更新其他依赖
pip install -r requirements_0.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

2. **验证安装**

```python
import torch
print(f"PyTorch 版本: {torch.__version__}")
print(f"CUDA 可用: {torch.cuda.is_available()}")
print(f"CUDA 版本: {torch.version.cuda}")
```

3. **重启服务**

```bash
# 停止旧服务
docker exec starpainting-digital-human-service-1 pkill -f "python app.py"

# 启动新服务
docker exec starpainting-digital-human-service-1 bash -c "source /opt/conda/etc/profile.d/conda.sh && conda activate human && cd /app/HeyGem-Linux-Python-Hack && nohup python app.py > /tmp/gradio.log 2>&1 &"
```

## 验证修复

1. **检查日志**：查看是否还有队列阻塞错误
2. **测试视频生成**：上传音频和视频文件，验证是否能正常生成
3. **监控资源**：使用 `nvidia-smi` 和 `top` 监控 GPU 和 CPU 使用情况

## 注意事项

1. **wenetmodel.pt 文件**：确保 wenet 模型文件已正确放置在指定路径
2. **CUDA 驱动**：确保 NVIDIA 驱动版本与 CUDA 11.8 兼容
3. **共享内存**：如果问题仍然存在，可以尝试增加共享内存大小到 4GB
4. **队列大小**：如果队列仍然满，可能需要检查服务代码中的队列大小配置

## 参考资源

- [PyTorch 官方文档 - 多进程数据加载](https://pytorch.org/docs/stable/data.html#multiprocessing-data-loading)
- [OpenCV 多线程问题解决方案](https://jishuzhan.net/article/1963186008134565890)
- [Docker 共享内存配置](https://developer.aliyun.com/article/1065418)

## 更新日期

2025-11-09

