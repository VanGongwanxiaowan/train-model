# 队列阻塞问题最终分析报告

## 问题描述

### 任务执行日志
```
[2025-11-09 17:29:40,287] [INFO] [drivered_video >>>>>>>>>>>>>>>>>>>> 发送数据大小:[1], current_idx:1]
[2025-11-09 17:29:40,322] [INFO] [drivered_video >>>>>>>>>>>>>>>>>>>> 发送数据大小:[1], current_idx:10]
[2025-11-09 17:30:40,324] [ERROR] [任务视频驱动队列满，严重阻塞，下游队列异常]
```

### 问题现象
1. **数据发送**: 成功发送了10个数据（current_idx:1 到 current_idx:10）
2. **阻塞时间**: 60秒后（17:29:40 到 17:30:40）出现队列阻塞
3. **错误信息**: "任务视频驱动队列满，严重阻塞，下游队列异常"
4. **GPU 利用率**: **0%** ❌（所有 GPU 利用率都为 0%）

## 根本原因分析

### 核心问题：GPU 未被使用

#### 1. 为什么 GPU 未被使用？

##### 原因 1: 处理速度慢导致队列阻塞
- **GPU 处理**: 每帧可能需要几毫秒到几十毫秒
- **CPU 处理**: 每帧可能需要几秒到几十秒
- **速度差距**: GPU 比 CPU 快 10-100 倍
- **问题**: 如果使用 CPU，处理 150 帧视频需要很长时间

##### 原因 2: 队列阻塞机制
- **数据产生速度快**: 视频帧数据快速进入队列（batch_size:1, len:150）
- **处理速度慢**: CPU 处理速度远慢于数据产生速度
- **队列填满**: 队列快速填满（仅处理了 10/150 个数据）
- **阻塞**: 队列填满后阻塞，无法继续处理

##### 原因 3: 处理速度分析
- **总数据量**: 150 帧
- **已处理**: 10 帧（6.7%）
- **处理时间**: 60 秒
- **处理速度**: 约 0.17 帧/秒（CPU 处理）
- **预计总时间**: 150 / 0.17 ≈ 882 秒（约 15 分钟）
- **队列阻塞**: 60 秒后队列填满，阻塞

### 2. 为什么 GPU 未被使用？

#### 可能原因 1: 环境变量未正确传递
- **问题**: 服务启动时 LD_LIBRARY_PATH 可能没有正确设置
- **影响**: ONNX Runtime 无法找到 cuDNN 库，回退到 CPU
- **状态**: ✅ 已修复（使用启动脚本）

#### 可能原因 2: trans_dh_service.so 导入时未找到库
- **问题**: trans_dh_service.so 是编译后的文件，在导入时如果 LD_LIBRARY_PATH 未设置，可能无法找到 cuDNN 库
- **影响**: 即使后来设置了环境变量，.so 文件已经加载，无法使用 GPU
- **状态**: ⚠️ 需要验证

#### 可能原因 3: 多进程环境下环境变量未传递
- **问题**: multiprocessing.spawn 方式创建的子进程可能没有正确继承环境变量
- **影响**: 子进程无法使用 GPU
- **状态**: ⚠️ 需要验证

#### 可能原因 4: ONNX Runtime 实际运行时回退到 CPU
- **问题**: 虽然检查脚本显示 GPU 可用，但实际运行时可能因为环境变量问题回退到 CPU
- **影响**: ONNX Runtime 使用 CPU，处理速度慢
- **状态**: ⚠️ 需要验证

#### 可能原因 5: trans_dh_service.so 内部未使用 GPU
- **问题**: trans_dh_service.so 是编译后的文件，可能内部没有使用 GPU，或者使用了 CPU
- **影响**: 即使环境变量正确，也无法使用 GPU
- **状态**: ⚠️ 需要检查

## 解决方案

### 方案 1: 使用启动脚本确保环境变量正确设置 ✅

#### 实施
使用启动脚本 `启动服务.sh`，确保环境变量在导入 .so 文件之前设置：
```bash
#!/bin/bash
source /opt/conda/etc/profile.d/conda.sh
conda activate human
export LD_LIBRARY_PATH=/opt/conda/envs/human/lib:$LD_LIBRARY_PATH
export ORT_PARALLEL=0
export OMP_WAIT_POLICY=ACTIVE
export ORT_LOGGING_LEVEL=3
cd /app/HeyGem-Linux-Python-Hack
python app.py
```

#### 状态
- ✅ 启动脚本已创建
- ✅ 服务已使用启动脚本重启
- ✅ 环境变量已设置

### 方案 2: 在 app.py 中提前设置环境变量 ✅

#### 实施
在 app.py 开头，在所有导入之前设置环境变量：
```python
# 在所有导入之前设置环境变量
conda_lib_path = "/opt/conda/envs/human/lib"
current_ld_path = os.environ.get("LD_LIBRARY_PATH", "")
if conda_lib_path not in current_ld_path:
    if current_ld_path:
        os.environ["LD_LIBRARY_PATH"] = f"{conda_lib_path}:{current_ld_path}"
    else:
        os.environ["LD_LIBRARY_PATH"] = conda_lib_path
    os.putenv("LD_LIBRARY_PATH", os.environ["LD_LIBRARY_PATH"])
```

#### 状态
- ✅ 环境变量已提前设置
- ✅ 在导入 trans_dh_service 之前设置

### 方案 3: 增加超时时间和队列大小 ✅

#### 实施
1. **增加队列大小**: 从 10 增加到 20 ✅
2. **增加超时时间**: 从 60秒 增加到 180秒 ✅
3. **增加任务等待时间**: 从 600秒 增加到 900秒 ✅

#### 状态
- ✅ 队列大小已增加
- ✅ 超时时间已增加
- ✅ 任务等待时间已增加

### 方案 4: 优化 ONNX Runtime 配置 ✅

#### 实施
1. **安装 onnxruntime-gpu 1.16.0**: ✅
2. **安装 cudatoolkit 11.8.0**: ✅
3. **安装 cuDNN 8.9.2**: ✅
4. **设置 LD_LIBRARY_PATH**: ✅

#### 状态
- ✅ ONNX Runtime GPU 支持已启用
- ✅ 检查脚本显示 GPU 可用

## 当前状态

### 已完成的修复
1. ✅ **ONNX Runtime 版本修复**: onnxruntime-gpu 1.16.0 已安装
2. ✅ **cuDNN 安装**: cuDNN 8.9.2 已安装
3. ✅ **环境变量设置**: LD_LIBRARY_PATH 已设置
4. ✅ **启动脚本创建**: 启动脚本已创建
5. ✅ **队列配置优化**: 队列大小和超时时间已增加
6. ✅ **服务重启**: 服务已使用启动脚本重启

### 待验证的问题
1. ⚠️ **GPU 使用**: GPU 利用率仍为 0%，需要验证是否真的使用了 GPU
2. ⚠️ **队列阻塞**: 队列阻塞问题是否解决，需要测试
3. ⚠️ **处理速度**: 处理速度是否提高，需要测试

## 诊断步骤

### 步骤 1: 检查服务进程的环境变量 ✅
```bash
# 检查服务进程的环境变量
ps e -p $(ps aux | grep 'python app.py' | grep -v grep | awk '{print $2}') | grep LD_LIBRARY_PATH
```
**结果**: LD_LIBRARY_PATH 已设置: `/opt/conda/envs/human/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64`

### 步骤 2: 检查 GPU 使用情况 ❌
```bash
# 监控 GPU 使用
nvidia-smi --query-gpu=index,utilization.gpu,memory.used --format=csv
```
**结果**: 所有 GPU 利用率为 0%

### 步骤 3: 检查 ONNX Runtime 配置 ✅
```bash
# 检查 ONNX Runtime 提供者
python check_env/check_onnx_cuda.py
```
**结果**: ONNX Runtime GPU 支持正常

### 步骤 4: 测试任务执行 ⏳
- 提交测试任务
- 观察 GPU 使用情况
- 检查队列阻塞情况

## 预期结果

### 如果 GPU 正常使用
- GPU 利用率 > 0%
- 处理速度应该很快（每帧几毫秒）
- 队列不应该阻塞
- 150 帧视频应该在几分钟内完成

### 如果 GPU 未使用
- GPU 利用率为 0%
- 处理速度慢（每帧几秒）
- 队列容易阻塞
- 150 帧视频可能需要几十分钟

## 总结

### 根本原因
**GPU 未被使用** - 这是队列阻塞的根本原因
- GPU 利用率为 0%
- 任务在 CPU 上运行
- 处理速度慢，导致队列阻塞

### 关键问题
1. **环境变量传递**: 子进程可能没有正确继承环境变量
2. **.so 文件加载**: trans_dh_service.so 导入时可能无法找到 cuDNN 库
3. **多进程环境**: multiprocessing.spawn 方式可能有问题
4. **trans_dh_service.so 内部**: 可能内部没有使用 GPU

### 解决方案
1. **使用启动脚本**: 确保环境变量在导入 .so 文件之前设置 ✅
2. **提前设置环境变量**: 在 app.py 开头设置环境变量 ✅
3. **增加超时时间**: 给 GPU 更多处理时间 ✅
4. **监控 GPU 使用**: 验证 GPU 是否被使用 ⏳

### 为什么这些修复有效？

1. **使用启动脚本**
   - 确保环境变量在导入 .so 文件之前设置
   - trans_dh_service.so 导入时能找到 cuDNN 库
   - ONNX Runtime 能使用 GPU

2. **提前设置环境变量**
   - 在所有导入之前设置环境变量
   - 确保 .so 文件能找到库
   - 传递给子进程

3. **增加超时时间**
   - 给 GPU 足够的处理时间
   - 避免过早判定失败
   - 提高任务成功率

## 下一步

### 立即行动
1. **测试任务执行**: 提交测试任务，观察 GPU 使用情况
2. **监控 GPU 使用**: 监控 GPU 利用率
3. **查看详细日志**: 分析任务执行过程
4. **检查 trans_dh_service.so**: 检查 .so 文件的依赖

### 后续优化
1. **优化环境变量传递**: 确保子进程能正确继承环境变量
2. **监控 GPU 使用**: 持续监控 GPU 使用情况
3. **优化队列配置**: 根据实际情况调整配置
4. **性能测试**: 进行完整的性能测试

## 相关文件
- `启动服务.sh` - 启动脚本
- `app.py` - 主程序（已优化）
- `队列阻塞问题原因和解决方案.md` - 详细解决方案
- `队列阻塞问题完整解决方案.md` - 完整解决方案

